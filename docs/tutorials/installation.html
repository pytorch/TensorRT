


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Installation &mdash; Torch-TensorRT master documentation</title>















  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Getting Started with C++" href="getting_started_with_cpp_api.html" />
    <link rel="prev" title="Torch-TensorRT" href="../index.html" />
  <!-- Google Analytics -->

  <!-- End Google Analytics -->



  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">





    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">





                <div class="version">
                  master (1.2.0a0+ffedb78)
                </div>









<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


          </div>







              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_cpp_api.html">Getting Started with C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_python_api.html">Using Torch-TensorRT in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="creating_torchscript_module_in_python.html">Creating a TorchScript Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="creating_torchscript_module_in_python.html#working-with-torchscript-in-python">Working with TorchScript in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="creating_torchscript_module_in_python.html#saving-torchscript-module-to-disk">Saving TorchScript Module to Disk</a></li>
<li class="toctree-l1"><a class="reference internal" href="ptq.html">Post Training Quantization (PTQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtrtc.html">torchtrtc</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_from_pytorch.html">Using Torch-TensorRT Directly From PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Deploying Torch-TensorRT Programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_dla.html">DLA</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving_torch_tensorrt_with_triton.html">Serving a Torch-TensorRT model with Triton</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/CitriNet-example.html">Torch-TensorRT Getting Started - CitriNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/dynamic-shapes.html">Torch-TensorRT - Using Dynamic Shapes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/EfficientNet-example.html">Torch-TensorRT Getting Started - EfficientNet-B0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/Hugging-Face-BERT.html">Masked Language Modeling (MLM) with Hugging Face BERT Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/lenet-getting-started.html">Torch-TensorRT Getting Started - LeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/Resnet50-example.html">Torch-TensorRT Getting Started - ResNet 50</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/ssd-object-detection-demo.html">Object Detection with Torch-TensorRT (SSD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_notebooks/vgg-qat.html">Deploying Quantization Aware Trained models in INT8 using Torch-TensorRT</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Documenation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../py_api/torch_tensorrt.html">torch_tensorrt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/logging.html">torch_tensorrt.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/ptq.html">torch_tensorrt.ptq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/ts.html">torch_tensorrt.ts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C++ API Documenation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/torch_tensort_cpp.html">Torch-TensorRT C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt.html">Namespace torch_tensorrt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__logging.html">Namespace torch_tensorrt::logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__torchscript.html">Namespace torch_tensorrt::torchscript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__ptq.html">Namespace torch_tensorrt::ptq</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contributor Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributors/system_overview.html">System Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors/writing_converters.html">Writing Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors/useful_links.html">Useful Links for Torch-TensorRT Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Indices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../indices/supported_ops.html">Operators Supported</a></li>
</ul>



        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">

      <li>
        <a href="../index.html">

            Docs

        </a> &gt;
      </li>


      <li>Installation</li>


      <li class="pytorch-breadcrumbs-aside">


            <a href="../_sources/tutorials/installation.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>


      </li>

  </ul>


</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">



          <div class="rst-content">

            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">

  <section id="installation">
<span id="id1"></span><h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<section id="precompiled-binaries">
<h2>Precompiled Binaries<a class="headerlink" href="#precompiled-binaries" title="Permalink to this headline">¶</a></h2>
<section id="dependencies">
<h3>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h3>
<p>You need to have either PyTorch or LibTorch installed based on if you are using Python or C++
and you must have CUDA, cuDNN and TensorRT installed.</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://www.pytorch.org">https://www.pytorch.org</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/cuda">https://developer.nvidia.com/cuda</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/tensorrt">https://developer.nvidia.com/tensorrt</a></p></li>
</ul>
</div></blockquote>
</section>
<section id="python-package">
<h3>Python Package<a class="headerlink" href="#python-package" title="Permalink to this headline">¶</a></h3>
<p>You can install the python package using</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip3 install torch-tensorrt -f https://github.com/pytorch/TensorRT/releases
</pre></div>
</div>
</section>
<section id="c-binary-distribution">
<span id="bin-dist"></span><h3>C++ Binary Distribution<a class="headerlink" href="#c-binary-distribution" title="Permalink to this headline">¶</a></h3>
<p>Precompiled tarballs for releases are provided here: <a class="reference external" href="https://github.com/pytorch/TensorRT/releases">https://github.com/pytorch/TensorRT/releases</a></p>
</section>
</section>
<section id="compiling-from-source">
<span id="compile-from-source"></span><h2>Compiling From Source<a class="headerlink" href="#compiling-from-source" title="Permalink to this headline">¶</a></h2>
<section id="dependencies-for-compilation">
<span id="installing-deps"></span><h3>Dependencies for Compilation<a class="headerlink" href="#dependencies-for-compilation" title="Permalink to this headline">¶</a></h3>
<p>Torch-TensorRT is built with Bazel, so begin by installing it.</p>
<blockquote>
<div><ul class="simple">
<li><p>The easiest way is to install bazelisk using the method of your choosing <a class="reference external" href="https://github.com/bazelbuild/bazelisk">https://github.com/bazelbuild/bazelisk</a></p></li>
<li><p>Otherwise you can use the following instructions to install binaries <a class="reference external" href="https://docs.bazel.build/versions/master/install.html">https://docs.bazel.build/versions/master/install.html</a></p></li>
<li><p>Finally if you need to compile from source (e.g. aarch64 until bazel distributes binaries for the architecture) you can use these instructions</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">BAZEL_VERSION</span><span class="o">=</span><span class="k">$(</span>cat &lt;PATH_TO_TORCHTRT_ROOT&gt;/.bazelversion<span class="k">)</span>
mkdir bazel
<span class="nb">cd</span> bazel
curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/<span class="nv">$BAZEL_VERSION</span>/bazel-<span class="nv">$BAZEL_VERSION</span>-dist.zip
unzip bazel-<span class="nv">$BAZEL_VERSION</span>-dist.zip
bash ./compile.sh
cp output/bazel /usr/local/bin/
</pre></div>
</div>
</div></blockquote>
<p>You will also need to have CUDA installed on the system (or if running in a container, the system must have
the CUDA driver installed and the container must have CUDA)</p>
<p>The correct LibTorch version will be pulled down for you by bazel.</p>
<blockquote>
<div><p>NOTE: For best compatability with official PyTorch, use torch==1.10.0+cuda113, TensorRT 8.0 and cuDNN 8.2 for CUDA 11.3 however Torch-TensorRT itself supports
TensorRT and cuDNN for other CUDA versions for usecases such as using NVIDIA compiled distributions of PyTorch that use other versions of CUDA
e.g. aarch64 or custom compiled version of PyTorch.</p>
</div></blockquote>
<section id="choosing-the-right-abi">
<span id="abis"></span><h4>Choosing the Right ABI<a class="headerlink" href="#choosing-the-right-abi" title="Permalink to this headline">¶</a></h4>
<p>Likely the most complicated thing about compiling Torch-TensorRT is selecting the correct ABI. There are two options
which are incompatible with each other, pre-cxx11-abi and the cxx11-abi. The complexity comes from the fact that while
the most popular distribution of PyTorch (wheels downloaded from pytorch.org/pypi directly) use the pre-cxx11-abi, most
other distributions you might encounter (e.g. ones from NVIDIA - NGC containers, and builds for Jetson as well as certain
libtorch builds and likely if you build PyTorch from source) use the cxx11-abi. It is important you compile Torch-TensorRT
using the correct ABI to function properly. Below is a table with general pairings of PyTorch distribution sources and the
recommended commands:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 31%" />
<col style="width: 36%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>PyTorch Source</p></th>
<th class="head"><p>Recommended C++ Compilation Command</p></th>
<th class="head"><p>Recommended Python Compilation Command</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>PyTorch whl file from PyTorch.org</p></td>
<td><p>bazel build //:libtorchtrt -c opt –config pre_cxx11_abi</p></td>
<td><p>python3 setup.py bdist_wheel</p></td>
</tr>
<tr class="row-odd"><td><p>libtorch-shared-with-deps-<a href="#id2"><span class="problematic" id="id3">*</span></a>.zip from PyTorch.org</p></td>
<td><p>bazel build //:libtorchtrt -c opt –config pre_cxx11_abi</p></td>
<td><p>python3 setup.py bdist_wheel</p></td>
</tr>
<tr class="row-even"><td><p>libtorch-cxx11-abi-shared-with-deps-<a href="#id4"><span class="problematic" id="id5">*</span></a>.zip from PyTorch.org</p></td>
<td><p>bazel build //:libtorchtrt -c opt</p></td>
<td><p>python3 setup.py bdist_wheel –use-cxx11-abi</p></td>
</tr>
<tr class="row-odd"><td><p>PyTorch preinstalled in an NGC container</p></td>
<td><p>bazel build //:libtorchtrt -c opt</p></td>
<td><p>python3 setup.py bdist_wheel –use-cxx11-abi</p></td>
</tr>
<tr class="row-even"><td><p>PyTorch from the NVIDIA Forums for Jetson</p></td>
<td><p>bazel build //:libtorchtrt -c opt</p></td>
<td><p>python3 setup.py bdist_wheel –jetpack-version 4.6 –use-cxx11-abi</p></td>
</tr>
<tr class="row-odd"><td><p>PyTorch built from Source</p></td>
<td><p>bazel build //:libtorchtrt -c opt</p></td>
<td><p>python3 setup.py bdist_wheel –use-cxx11-abi</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>NOTE: For all of the above cases you must correctly declare the source of PyTorch you intend to use in your WORKSPACE file for both Python and C++ builds. See below for more information</p>
</div></blockquote>
<p>You then have two compilation options:</p>
</section>
</section>
<section id="building-using-cudnn-tensorrt-tarball-distributions">
<span id="build-from-archive"></span><h3><strong>Building using cuDNN &amp; TensorRT tarball distributions</strong><a class="headerlink" href="#building-using-cudnn-tensorrt-tarball-distributions" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>This is recommended so as to build Torch-TensorRT hermetically and insures any compilation errors are not caused by version issues</p>
<p>Make sure when running Torch-TensorRT that these versions of the libraries are prioritized in your <code class="docutils literal notranslate"><span class="pre">$LD_LIBRARY_PATH</span></code></p>
</div></blockquote>
<dl class="simple">
<dt>You need to download the tarball distributions of TensorRT and cuDNN from the NVIDIA website.</dt><dd><ul class="simple">
<li><p><a class="reference external" href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/tensorrt">https://developer.nvidia.com/tensorrt</a></p></li>
</ul>
</dd>
</dl>
<p>Place these files in a directory (the directories <code class="docutils literal notranslate"><span class="pre">third_party/distdir/[x86_64-linux-gnu</span> <span class="pre">|</span> <span class="pre">aarch64-linux-gnu]</span></code> exist for this purpose)</p>
<p>Then compile referencing the directory with the tarballs</p>
<blockquote>
<div><p>If you get errors regarding the packages, check their sha256 hashes and make sure they match the ones listed in <code class="docutils literal notranslate"><span class="pre">WORKSPACE</span></code></p>
</div></blockquote>
<section id="release-build">
<h4>Release Build<a class="headerlink" href="#release-build" title="Permalink to this headline">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt -c opt --distdir third_party/distdir/<span class="o">[</span>x86_64-linux-gnu <span class="p">|</span> aarch64-linux-gnu<span class="o">]</span>
</pre></div>
</div>
<p>A tarball with the include files and library can then be found in <code class="docutils literal notranslate"><span class="pre">bazel-bin</span></code></p>
</section>
<section id="debug-build">
<span id="build-from-archive-debug"></span><h4>Debug Build<a class="headerlink" href="#debug-build" title="Permalink to this headline">¶</a></h4>
<p>To build with debug symbols use the following command</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt -c dbg --distdir third_party/distdir/<span class="o">[</span>x86_64-linux-gnu <span class="p">|</span> aarch64-linux-gnu<span class="o">]</span>
</pre></div>
</div>
<p>A tarball with the include files and library can then be found in <code class="docutils literal notranslate"><span class="pre">bazel-bin</span></code></p>
</section>
<section id="pre-cxx11-abi-build">
<h4>Pre CXX11 ABI Build<a class="headerlink" href="#pre-cxx11-abi-build" title="Permalink to this headline">¶</a></h4>
<p>To build using the pre-CXX11 ABI use the <code class="docutils literal notranslate"><span class="pre">pre_cxx11_abi</span></code> config</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt --config pre_cxx11_abi -c <span class="o">[</span>dbg/opt<span class="o">]</span> --distdir third_party/distdir/<span class="o">[</span>x86_64-linux-gnu <span class="p">|</span> aarch64-linux-gnu<span class="o">]</span>
</pre></div>
</div>
<p>A tarball with the include files and library can then be found in <code class="docutils literal notranslate"><span class="pre">bazel-bin</span></code></p>
</section>
</section>
<section id="building-using-locally-installed-cudnn-tensorrt">
<span id="build-from-local"></span><h3><strong>Building using locally installed cuDNN &amp; TensorRT</strong><a class="headerlink" href="#building-using-locally-installed-cudnn-tensorrt" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>If you encounter bugs and you compiled using this method please disclose that you used local sources in the issue (an ldd dump would be nice too)</p>
</div></blockquote>
<p>Install TensorRT, CUDA and cuDNN on the system before starting to compile.</p>
<p>In WORKSPACE comment out:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Downloaded distributions to use with --distdir</span>
<span class="n">http_archive</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span><span class="p">,</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;URL&gt;&quot;</span><span class="p">,],</span>

    <span class="n">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/cudnn/archive:BUILD&quot;</span><span class="p">,</span>
    <span class="n">sha256</span> <span class="o">=</span> <span class="s2">&quot;&lt;TAR SHA256&gt;&quot;</span><span class="p">,</span>
    <span class="n">strip_prefix</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
<span class="p">)</span>

<span class="n">http_archive</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;tensorrt&quot;</span><span class="p">,</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;URL&gt;&quot;</span><span class="p">,],</span>

    <span class="n">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/tensorrt/archive:BUILD&quot;</span><span class="p">,</span>
    <span class="n">sha256</span> <span class="o">=</span> <span class="s2">&quot;&lt;TAR SHA256&gt;&quot;</span><span class="p">,</span>
    <span class="n">strip_prefix</span> <span class="o">=</span> <span class="s2">&quot;TensorRT-&lt;VERSION&gt;&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>and uncomment</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Locally installed dependencies</span>
<span class="n">new_local_repository</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span><span class="p">,</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/&quot;</span><span class="p">,</span>
    <span class="n">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/cudnn/local:BUILD&quot;</span>
<span class="p">)</span>

<span class="n">new_local_repository</span><span class="p">(</span>
<span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;tensorrt&quot;</span><span class="p">,</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/&quot;</span><span class="p">,</span>
<span class="n">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/tensorrt/local:BUILD&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<section id="id6">
<h4>Release Build<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>Compile using:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt -c opt
</pre></div>
</div>
<p>A tarball with the include files and library can then be found in <code class="docutils literal notranslate"><span class="pre">bazel-bin</span></code></p>
</section>
<section id="build-from-local-debug">
<span id="id7"></span><h4>Debug Build<a class="headerlink" href="#build-from-local-debug" title="Permalink to this headline">¶</a></h4>
<p>To build with debug symbols use the following command</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt -c dbg
</pre></div>
</div>
<p>A tarball with the include files and library can then be found in <code class="docutils literal notranslate"><span class="pre">bazel-bin</span></code></p>
</section>
<section id="id8">
<h4>Pre CXX11 ABI Build<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>To build using the pre-CXX11 ABI use the <code class="docutils literal notranslate"><span class="pre">pre_cxx11_abi</span></code> config</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt --config pre_cxx11_abi -c <span class="o">[</span>dbg/opt<span class="o">]</span>
</pre></div>
</div>
</section>
</section>
<section id="building-the-python-package">
<h3><strong>Building the Python package</strong><a class="headerlink" href="#building-the-python-package" title="Permalink to this headline">¶</a></h3>
<p>Begin by installing <code class="docutils literal notranslate"><span class="pre">ninja</span></code></p>
<p>You can build the Python package using <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> (this will also build the correct version of <code class="docutils literal notranslate"><span class="pre">libtorchtrt.so</span></code>)</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3 setup.py <span class="o">[</span>install/bdist_wheel<span class="o">]</span>
</pre></div>
</div>
<section id="id9">
<h4>Debug Build<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3 setup.py develop <span class="o">[</span>--user<span class="o">]</span>
</pre></div>
</div>
<p>This also compiles a debug build of <code class="docutils literal notranslate"><span class="pre">libtorchtrt.so</span></code></p>
</section>
</section>
<section id="building-natively-on-aarch64-jetson">
<h3><strong>Building Natively on aarch64 (Jetson)</strong><a class="headerlink" href="#building-natively-on-aarch64-jetson" title="Permalink to this headline">¶</a></h3>
<section id="prerequisites">
<h4>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h4>
<p>Install or compile a build of PyTorch/LibTorch for aarch64</p>
<p>NVIDIA hosts builds the latest release branch for Jetson here:</p>
<blockquote>
<div><p><a class="reference external" href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048">https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048</a></p>
</div></blockquote>
</section>
<section id="enviorment-setup">
<h4>Enviorment Setup<a class="headerlink" href="#enviorment-setup" title="Permalink to this headline">¶</a></h4>
<p>To build natively on aarch64-linux-gnu platform, configure the <code class="docutils literal notranslate"><span class="pre">WORKSPACE</span></code> with local available dependencies.</p>
<ol class="arabic simple">
<li><p>Disable the rules with <code class="docutils literal notranslate"><span class="pre">http_archive</span></code> for x86_64 by commenting the following rules:</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#http_archive(</span>
<span class="c1">#    name = &quot;libtorch&quot;,</span>
<span class="c1">#    build_file = &quot;@//third_party/libtorch:BUILD&quot;,</span>
<span class="c1">#    strip_prefix = &quot;libtorch&quot;,</span>
<span class="c1">#    urls = [&quot;https://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.5.1.zip&quot;],</span>
<span class="c1">#    sha256 = &quot;cf0691493d05062fe3239cf76773bae4c5124f4b039050dbdd291c652af3ab2a&quot;</span>
<span class="c1">#)</span>

<span class="c1">#http_archive(</span>
<span class="c1">#    name = &quot;libtorch_pre_cxx11_abi&quot;,</span>
<span class="c1">#    build_file = &quot;@//third_party/libtorch:BUILD&quot;,</span>
<span class="c1">#    strip_prefix = &quot;libtorch&quot;,</span>
<span class="c1">#    sha256 = &quot;818977576572eadaf62c80434a25afe44dbaa32ebda3a0919e389dcbe74f8656&quot;,</span>
<span class="c1">#    urls = [&quot;https://download.pytorch.org/libtorch/cu102/libtorch-shared-with-deps-1.5.1.zip&quot;],</span>
<span class="c1">#)</span>

<span class="c1"># Download these tarballs manually from the NVIDIA website</span>
<span class="c1"># Either place them in the distdir directory in third_party and use the --distdir flag</span>
<span class="c1"># or modify the urls to &quot;file:///&lt;PATH TO TARBALL&gt;/&lt;TARBALL NAME&gt;.tar.gz</span>

<span class="c1">#http_archive(</span>
<span class="c1">#    name = &quot;cudnn&quot;,</span>
<span class="c1">#    urls = [&quot;https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.0.1.13/10.2_20200626/cudnn-10.2-linux-x64-v8.0.1.13.tgz&quot;],</span>
<span class="c1">#    build_file = &quot;@//third_party/cudnn/archive:BUILD&quot;,</span>
<span class="c1">#    sha256 = &quot;0c106ec84f199a0fbcf1199010166986da732f9b0907768c9ac5ea5b120772db&quot;,</span>
<span class="c1">#    strip_prefix = &quot;cuda&quot;</span>
<span class="c1">#)</span>

<span class="c1">#http_archive(</span>
<span class="c1">#    name = &quot;tensorrt&quot;,</span>
<span class="c1">#    urls = [&quot;https://developer.nvidia.com/compute/machine-learning/tensorrt/secure/7.1/tars/TensorRT-7.1.3.4.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn8.0.tar.gz&quot;],</span>
<span class="c1">#    build_file = &quot;@//third_party/tensorrt/archive:BUILD&quot;,</span>
<span class="c1">#    sha256 = &quot;9205bed204e2ae7aafd2e01cce0f21309e281e18d5bfd7172ef8541771539d41&quot;,</span>
<span class="c1">#    strip_prefix = &quot;TensorRT-7.1.3.4&quot;</span>
<span class="c1">#)</span>

NOTE: You may also need to configure the CUDA version to <span class="m">10</span>.2 by setting the path <span class="k">for</span> the cuda new_local_repository
</pre></div>
</div>
<ol class="arabic" start="2">
<li><p>Configure the correct paths to directory roots containing local dependencies in the <code class="docutils literal notranslate"><span class="pre">new_local_repository</span></code> rules:</p>
<blockquote>
<div><p>NOTE: If you installed PyTorch using a pip package, the correct path is the path to the root of the python torch package.
In the case that you installed with <code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">pip</span> <span class="pre">install</span></code> this will be <code class="docutils literal notranslate"><span class="pre">/usr/local/lib/python3.6/dist-packages/torch</span></code>.
In the case you installed with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">--user</span></code> this will be <code class="docutils literal notranslate"><span class="pre">$HOME/.local/lib/python3.6/site-packages/torch</span></code>.</p>
</div></blockquote>
</li>
</ol>
<p>In the case you are using NVIDIA compiled pip packages, set the path for both libtorch sources to the same path. This is because unlike
PyTorch on x86_64, NVIDIA aarch64 PyTorch uses the CXX11-ABI. If you compiled for source using the pre_cxx11_abi and only would like to
use that library, set the paths to the same path but when you compile make sure to add the flag <code class="docutils literal notranslate"><span class="pre">--config=pre_cxx11_abi</span></code></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>new_local_repository<span class="o">(</span>
    <span class="nv">name</span> <span class="o">=</span> <span class="s2">&quot;libtorch&quot;</span>,
    <span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/local/lib/python3.6/dist-packages/torch&quot;</span>,
    <span class="nv">build_file</span> <span class="o">=</span> <span class="s2">&quot;third_party/libtorch/BUILD&quot;</span>
<span class="o">)</span>

new_local_repository<span class="o">(</span>
    <span class="nv">name</span> <span class="o">=</span> <span class="s2">&quot;libtorch_pre_cxx11_abi&quot;</span>,
    <span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/local/lib/python3.6/dist-packages/torch&quot;</span>,
    <span class="nv">build_file</span> <span class="o">=</span> <span class="s2">&quot;third_party/libtorch/BUILD&quot;</span>
<span class="o">)</span>

new_local_repository<span class="o">(</span>
    <span class="nv">name</span> <span class="o">=</span> <span class="s2">&quot;cudnn&quot;</span>,
    <span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/&quot;</span>,
    <span class="nv">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/cudnn/local:BUILD&quot;</span>
<span class="o">)</span>

new_local_repository<span class="o">(</span>
    <span class="nv">name</span> <span class="o">=</span> <span class="s2">&quot;tensorrt&quot;</span>,
    <span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;/usr/&quot;</span>,
    <span class="nv">build_file</span> <span class="o">=</span> <span class="s2">&quot;@//third_party/tensorrt/local:BUILD&quot;</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="compile-c-library-and-compiler-cli">
<h4>Compile C++ Library and Compiler CLI<a class="headerlink" href="#compile-c-library-and-compiler-cli" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>NOTE: Due to shifting dependency locations between Jetpack 4.5 and 4.6 there is a now a flag to inform bazel of the Jetpack version</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>--platforms //toolchains:jetpack_4.x
</pre></div>
</div>
</div></blockquote>
<p>Compile Torch-TensorRT library using bazel command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bazel build //:libtorchtrt --platforms //toolchains:jetpack_4.6
</pre></div>
</div>
</section>
<section id="compile-python-api">
<h4>Compile Python API<a class="headerlink" href="#compile-python-api" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>NOTE: Due to shifting dependencies locations between Jetpack 4.5 and Jetpack 4.6 there is now a flag for <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> which sets the jetpack version (default: 4.6)</p>
</div></blockquote>
<p>Compile the Python API using the following command from the <code class="docutils literal notranslate"><span class="pre">//py</span></code> directory:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3 setup.py install --use-cxx11-abi
</pre></div>
</div>
<p>If you have a build of PyTorch that uses Pre-CXX11 ABI drop the <code class="docutils literal notranslate"><span class="pre">--use-cxx11-abi</span></code> flag</p>
<p>If you are building for Jetpack 4.5 add the <code class="docutils literal notranslate"><span class="pre">--jetpack-version</span> <span class="pre">4.5</span></code> flag</p>
</section>
</section>
</section>
</section>


             </article>

            </div>
            <footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">

        <a href="getting_started_with_cpp_api.html" class="btn btn-neutral float-right" title="Getting Started with C++" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>


        <a href="../index.html" class="btn btn-neutral" title="Torch-TensorRT" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>

    </div>




    <hr>



  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, NVIDIA Corporation.

    </p>
  </div>

      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>


</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Installation</a><ul>
<li><a class="reference internal" href="#precompiled-binaries">Precompiled Binaries</a><ul>
<li><a class="reference internal" href="#dependencies">Dependencies</a></li>
<li><a class="reference internal" href="#python-package">Python Package</a></li>
<li><a class="reference internal" href="#c-binary-distribution">C++ Binary Distribution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#compiling-from-source">Compiling From Source</a><ul>
<li><a class="reference internal" href="#dependencies-for-compilation">Dependencies for Compilation</a><ul>
<li><a class="reference internal" href="#choosing-the-right-abi">Choosing the Right ABI</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-using-cudnn-tensorrt-tarball-distributions"><strong>Building using cuDNN &amp; TensorRT tarball distributions</strong></a><ul>
<li><a class="reference internal" href="#release-build">Release Build</a></li>
<li><a class="reference internal" href="#debug-build">Debug Build</a></li>
<li><a class="reference internal" href="#pre-cxx11-abi-build">Pre CXX11 ABI Build</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-using-locally-installed-cudnn-tensorrt"><strong>Building using locally installed cuDNN &amp; TensorRT</strong></a><ul>
<li><a class="reference internal" href="#id6">Release Build</a></li>
<li><a class="reference internal" href="#build-from-local-debug">Debug Build</a></li>
<li><a class="reference internal" href="#id8">Pre CXX11 ABI Build</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-the-python-package"><strong>Building the Python package</strong></a><ul>
<li><a class="reference internal" href="#id9">Debug Build</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-natively-on-aarch64-jetson"><strong>Building Natively on aarch64 (Jetson)</strong></a><ul>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#enviorment-setup">Enviorment Setup</a></li>
<li><a class="reference internal" href="#compile-c-library-and-compiler-cli">Compile C++ Library and Compiler CLI</a></li>
<li><a class="reference internal" href="#compile-python-api">Compile Python API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>







       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
         <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
         <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>




  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>