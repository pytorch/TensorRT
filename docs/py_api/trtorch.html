<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="width=device-width,initial-scale=1" name="viewport"/>
  <meta content="ie=edge" http-equiv="x-ua-compatible"/>
  <meta content="Copy to clipboard" name="lang:clipboard.copy"/>
  <meta content="Copied to clipboard" name="lang:clipboard.copied"/>
  <meta content="en" name="lang:search.language"/>
  <meta content="True" name="lang:search.pipeline.stopwords"/>
  <meta content="True" name="lang:search.pipeline.trimmer"/>
  <meta content="No matching documents" name="lang:search.result.none"/>
  <meta content="1 matching document" name="lang:search.result.one"/>
  <meta content="# matching documents" name="lang:search.result.other"/>
  <meta content="[\s\-]+" name="lang:search.tokenizer"/>
  <link crossorigin="" href="https://fonts.gstatic.com/" rel="preconnect"/>
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&amp;display=fallback" rel="stylesheet"/>
  <style>
   body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
  </style>
  <link href="../_static/stylesheets/application.css" rel="stylesheet"/>
  <link href="../_static/stylesheets/application-palette.css" rel="stylesheet"/>
  <link href="../_static/stylesheets/application-fixes.css" rel="stylesheet"/>
  <link href="../_static/fonts/material-icons.css" rel="stylesheet"/>
  <meta content="84bd00" name="theme-color"/>
  <script src="../_static/javascripts/modernizr.js">
  </script>
  <title>
   trtorch — TRTorch master documentation
  </title>
  <link href="../_static/material.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/collapsible-lists/css/tree_view.css" rel="stylesheet" type="text/css"/>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js">
  </script>
  <script src="../_static/jquery.js">
  </script>
  <script src="../_static/underscore.js">
  </script>
  <script src="../_static/doctools.js">
  </script>
  <script src="../_static/language_data.js">
  </script>
  <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js">
  </script>
  <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js">
  </script>
  <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js">
  </script>
  <link href="../genindex.html" rel="index" title="Index"/>
  <link href="../search.html" rel="search" title="Search"/>
  <link href="logging.html" rel="next" title="trtorch.logging"/>
  <link href="../_notebooks/ssd-object-detection-demo.html" rel="prev" title="Object Detection with TRTorch (SSD)"/>
 </head>
 <body data-md-color-accent="light-green" data-md-color-primary="light-green" dir="ltr">
  <svg class="md-svg">
   <defs data-children-count="0">
    <svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg">
     <path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor">
     </path>
    </svg>
   </defs>
  </svg>
  <input class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
  <input class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
  <label class="md-overlay" data-md-component="overlay" for="__drawer">
  </label>
  <a class="md-skip" href="#py_api/trtorch" tabindex="1">
   Skip to content
  </a>
  <header class="md-header" data-md-component="header">
   <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
     <div class="md-flex__cell md-flex__cell--shrink">
      <a class="md-header-nav__button md-logo" href="../index.html" title="TRTorch master documentation">
       <i class="md-icon">
        
       </i>
      </a>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer">
      </label>
     </div>
     <div class="md-flex__cell md-flex__cell--stretch">
      <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
       <span class="md-header-nav__topic">
        TRTorch
       </span>
       <span class="md-header-nav__topic">
        trtorch
       </span>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <label class="md-icon md-icon--search md-header-nav__button" for="__search">
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
       <label class="md-search__overlay" for="__search">
       </label>
       <div class="md-search__inner" role="search">
        <form action="../search.html" class="md-search__form" method="GET" name="search">
         <input autocapitalize="off" autocomplete="off" class="md-search__input" data-md-component="query" data-md-state="active" name="q" placeholder="Search" spellcheck="false" type="text"/>
         <label class="md-icon md-search__icon" for="__search">
         </label>
         <button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
          
         </button>
        </form>
        <div class="md-search__output">
         <div class="md-search__scrollwrap" data-md-scrollfix="">
          <div class="md-search-result" data-md-component="result">
           <div class="md-search-result__meta">
            Type to start searching
           </div>
           <ol class="md-search-result__list">
           </ol>
          </div>
         </div>
        </div>
       </div>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink">
      <div class="md-header-nav__source">
       <a class="md-source" data-md-source="github" href="https://github.com/nvidia/TRTorch/" title="Go to repository">
        <div class="md-source__icon">
         <svg height="28" viewbox="0 0 24 24" width="28" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
          <use height="24" width="24" xlink:href="#__github">
          </use>
         </svg>
        </div>
        <div class="md-source__repository">
         TRTorch
        </div>
       </a>
      </div>
     </div>
     <div class="md-flex__cell md-flex__cell--shrink dropdown">
      <button class="dropdownbutton">
       Versions
      </button>
      <div class="dropdown-content md-hero">
       <a href="https://nvidia.github.io/TRTorch/" title="master">
        master
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.1.0/" title="v0.1.0">
        v0.1.0
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.3/" title="v0.0.3">
        v0.0.3
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.2/" title="v0.0.2">
        v0.0.2
       </a>
       <a href="https://nvidia.github.io/TRTorch/v0.0.1/" title="v0.0.1">
        v0.0.1
       </a>
      </div>
     </div>
    </div>
   </nav>
  </header>
  <div class="md-container">
   <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
     <ul class="md-tabs__list">
      <li class="md-tabs__item">
       <a class="md-tabs__link" href="../index.html">
        TRTorch master documentation
       </a>
      </li>
     </ul>
    </div>
   </nav>
   <main class="md-main">
    <div class="md-main__inner md-grid" data-md-component="container">
     <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav class="md-nav md-nav--primary" data-md-level="0">
         <label class="md-nav__title md-nav__title--site" for="__drawer">
          <a class="md-nav__button md-logo" href="../index.html" title="TRTorch master documentation">
           <i class="md-icon">
            
           </i>
          </a>
          <a href="../index.html" title="TRTorch master documentation">
           TRTorch
          </a>
         </label>
         <div class="md-nav__source">
          <a class="md-source" data-md-source="github" href="https://github.com/nvidia/TRTorch/" title="Go to repository">
           <div class="md-source__icon">
            <svg height="28" viewbox="0 0 24 24" width="28" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
             <use height="24" width="24" xlink:href="#__github">
             </use>
            </svg>
           </div>
           <div class="md-source__repository">
            TRTorch
           </div>
          </a>
         </div>
         <ul class="md-nav__list">
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Getting Started
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/installation.html">
            Installation
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/getting_started.html">
            Getting Started
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/ptq.html">
            Post Training Quantization (PTQ)
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/trtorchc.html">
            trtorchc
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/use_from_pytorch.html">
            Using TRTorch Directly From PyTorch
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/runtime.html">
            Deploying TRTorch Programs
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../tutorials/using_dla.html">
            DLA
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Notebooks
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_notebooks/lenet-getting-started.html">
            TRTorch Getting Started - LeNet
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_notebooks/ssd-object-detection-demo.html">
            Object Detection with TRTorch (SSD)
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Python API Documenation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
           <label class="md-nav__link md-nav__link--active" for="__toc">
            trtorch
           </label>
           <a class="md-nav__link md-nav__link--active" href="#">
            trtorch
           </a>
           <nav class="md-nav md-nav--secondary">
            <label class="md-nav__title" for="__toc">
             Contents
            </label>
            <ul class="md-nav__list" data-md-scrollfix="">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#py-api-trtorch--page-root">
               trtorch
              </a>
              <nav class="md-nav">
               <ul class="md-nav__list">
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#functions">
                  Functions
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#enums">
                  Enums
                 </a>
                </li>
                <li class="md-nav__item">
                 <a class="md-nav__link" href="#submodules">
                  Submodules
                 </a>
                </li>
               </ul>
              </nav>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__extra_link" href="../_sources/py_api/trtorch.rst.txt">
               Show Source
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="logging.html">
            trtorch.logging
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             C++ API Documenation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../_cpp_api/trtorch_cpp.html">
            TRTorch C++ API
           </a>
          </li>
          <li class="md-nav__item">
           <span class="md-nav__link caption">
            <span class="caption-text">
             Contributor Documentation
            </span>
           </span>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/system_overview.html">
            System Overview
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/writing_converters.html">
            Writing Converters
           </a>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__link" href="../contributors/useful_links.html">
            Useful Links for TRTorch Development
           </a>
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
      <div class="md-sidebar__scrollwrap">
       <div class="md-sidebar__inner">
        <nav class="md-nav md-nav--secondary">
         <label class="md-nav__title" for="__toc">
          Contents
         </label>
         <ul class="md-nav__list" data-md-scrollfix="">
          <li class="md-nav__item">
           <a class="md-nav__link" href="#py-api-trtorch--page-root">
            trtorch
           </a>
           <nav class="md-nav">
            <ul class="md-nav__list">
             <li class="md-nav__item">
              <a class="md-nav__link" href="#functions">
               Functions
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#enums">
               Enums
              </a>
             </li>
             <li class="md-nav__item">
              <a class="md-nav__link" href="#submodules">
               Submodules
              </a>
             </li>
            </ul>
           </nav>
          </li>
          <li class="md-nav__item">
           <a class="md-nav__extra_link" href="../_sources/py_api/trtorch.rst.txt">
            Show Source
           </a>
          </li>
          <li class="md-nav__item" id="searchbox">
          </li>
         </ul>
        </nav>
       </div>
      </div>
     </div>
     <div class="md-content">
      <article class="md-content__inner md-typeset" role="main">
       <span id="trtorch">
       </span>
       <span id="trtorch-py">
       </span>
       <h1 id="py-api-trtorch--page-root">
        trtorch
        <a class="headerlink" href="#py-api-trtorch--page-root" title="Permalink to this headline">
         ¶
        </a>
       </h1>
       <h2 id="functions">
        Functions
        <a class="headerlink" href="#functions" title="Permalink to this headline">
         ¶
        </a>
       </h2>
       <dl class="py function">
        <dt id="trtorch.compile">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          compile
         </code>
         <span class="sig-paren">
          (
         </span>
         <em class="sig-param">
          <span class="n">
           module
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           torch.jit._script.ScriptModule
          </span>
         </em>
         ,
         <em class="sig-param">
          <span class="n">
           compile_spec
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           Any
          </span>
         </em>
         <span class="sig-paren">
          )
         </span>
         → torch.jit._script.ScriptModule
         <a class="headerlink" href="#trtorch.compile" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Compile a TorchScript module for NVIDIA GPUs using TensorRT
         </p>
         <p>
          Takes a existing TorchScript module and a set of settings to configure the compiler
and will convert methods to JIT Graphs which call equivalent TensorRT engines
         </p>
         <p>
          Converts specifically the forward method of a TorchScript Module
         </p>
         <dl class="field-list simple">
          <dt class="field-odd">
           Parameters
          </dt>
          <dd class="field-odd">
           <ul class="simple">
            <li>
             <p>
              <strong>
               module
              </strong>
              (
              <em>
               torch.jit.ScriptModule
              </em>
              ) – Source module, a result of tracing or scripting a PyTorch
              <code class="docutils literal notranslate">
               <span class="pre">
                torch.nn.Module
               </span>
              </code>
             </p>
            </li>
            <li>
             <p>
              <strong>
               compile_spec
              </strong>
              (
              <em>
               dict
              </em>
              ) –
             </p>
             <p>
              Compilation settings including operating precision, target device, etc.
One key is required which is
              <code class="docutils literal notranslate">
               <span class="pre">
                input_shapes
               </span>
              </code>
              , describing the input sizes or ranges for inputs
to the graph. All other keys are optional
             </p>
             <div class="highlight-py notranslate">
              <div class="highlight">
               <pre><span></span><span class="n">compile_spec</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"input_shapes"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="c1"># Static input shape for input #1</span>
        <span class="p">{</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
            <span class="s2">"opt"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="p">}</span> <span class="c1"># Dynamic input shape for input #2</span>
    <span class="p">],</span>
    <span class="s2">"device"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"device_type"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="c1"># Type of device to run engine on (for DLA use trtorch.DeviceType.DLA)</span>
        <span class="s2">"gpu_id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Target gpu id to run engine (Use Xavier as gpu id for DLA)</span>
        <span class="s2">"dla_core"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># (DLA only) Target dla core id to run engine</span>
        <span class="s2">"allow_gpu_fallback"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># (DLA only) Allow layers unsupported on DLA to run on GPU</span>
    <span class="p">},</span>
    <span class="s2">"op_precision"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="c1"># Operating precision set to FP16</span>
    <span class="s2">"refit"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># enable refit</span>
    <span class="s2">"debug"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># enable debuggable engine</span>
    <span class="s2">"strict_types"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># kernels should strictly run in operating precision</span>
    <span class="s2">"capability"</span><span class="p">:</span> <span class="n">trtorch</span><span class="o">.</span><span class="n">EngineCapability</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="c1"># Restrict kernel selection to safe gpu kernels or safe dla kernels</span>
    <span class="s2">"num_min_timing_iters"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># Number of minimization timing iterations used to select kernels</span>
    <span class="s2">"num_avg_timing_iters"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># Number of averaging timing iterations used to select kernels</span>
    <span class="s2">"workspace_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum size of workspace given to TensorRT</span>
    <span class="s2">"max_batch_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum batch size (must be &gt;= 1 to be set, 0 means not set)</span>
<span class="p">}</span>
</pre>
              </div>
             </div>
             <p>
              Input Sizes can be specified as torch sizes, tuples or lists. Op precisions can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
             </p>
            </li>
           </ul>
          </dd>
          <dt class="field-even">
           Returns
          </dt>
          <dd class="field-even">
           <p>
            Compiled TorchScript Module, when run it will execute via TensorRT
           </p>
          </dd>
          <dt class="field-odd">
           Return type
          </dt>
          <dd class="field-odd">
           <p>
            torch.jit.ScriptModule
           </p>
          </dd>
         </dl>
        </dd>
       </dl>
       <dl class="py function">
        <dt id="trtorch.convert_method_to_trt_engine">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          convert_method_to_trt_engine
         </code>
         <span class="sig-paren">
          (
         </span>
         <em class="sig-param">
          <span class="n">
           module
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           torch.jit._script.ScriptModule
          </span>
         </em>
         ,
         <em class="sig-param">
          <span class="n">
           method_name
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           str
          </span>
         </em>
         ,
         <em class="sig-param">
          <span class="n">
           compile_spec
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           Any
          </span>
         </em>
         <span class="sig-paren">
          )
         </span>
         → str
         <a class="headerlink" href="#trtorch.convert_method_to_trt_engine" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Convert a TorchScript module method to a serialized TensorRT engine
         </p>
         <p>
          Converts a specified method of a module to a serialized TensorRT engine given a dictionary of conversion settings
         </p>
         <dl class="field-list simple">
          <dt class="field-odd">
           Parameters
          </dt>
          <dd class="field-odd">
           <ul class="simple">
            <li>
             <p>
              <strong>
               module
              </strong>
              (
              <em>
               torch.jit.ScriptModule
              </em>
              ) – Source module, a result of tracing or scripting a PyTorch
              <code class="docutils literal notranslate">
               <span class="pre">
                torch.nn.Module
               </span>
              </code>
             </p>
            </li>
            <li>
             <p>
              <strong>
               method_name
              </strong>
              (
              <em>
               str
              </em>
              ) – Name of method to convert
             </p>
            </li>
            <li>
             <p>
              <strong>
               compile_spec
              </strong>
              (
              <em>
               dict
              </em>
              ) –
             </p>
             <p>
              Compilation settings including operating precision, target device, etc.
One key is required which is
              <code class="docutils literal notranslate">
               <span class="pre">
                input_shapes
               </span>
              </code>
              , describing the input sizes or ranges for inputs
to the graph. All other keys are optional
             </p>
             <div class="highlight-py notranslate">
              <div class="highlight">
               <pre><span></span><span class="n">CompileSpec</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"input_shapes"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="c1"># Static input shape for input #1</span>
        <span class="p">{</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
            <span class="s2">"opt"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="p">}</span> <span class="c1"># Dynamic input shape for input #2</span>
    <span class="p">],</span>
    <span class="s2">"device"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"device_type"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="c1"># Type of device to run engine on (for DLA use trtorch.DeviceType.DLA)</span>
        <span class="s2">"gpu_id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Target gpu id to run engine (Use Xavier as gpu id for DLA)</span>
        <span class="s2">"dla_core"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># (DLA only) Target dla core id to run engine</span>
        <span class="s2">"allow_gpu_fallback"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># (DLA only) Allow layers unsupported on DLA to run on GPU</span>
    <span class="p">},</span>
    <span class="s2">"op_precision"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="c1"># Operating precision set to FP16</span>
    <span class="s2">"refit"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># enable refit</span>
    <span class="s2">"debug"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># enable debuggable engine</span>
    <span class="s2">"strict_types"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># kernels should strictly run in operating precision</span>
    <span class="s2">"capability"</span><span class="p">:</span> <span class="n">trtorch</span><span class="o">.</span><span class="n">EngineCapability</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="c1"># Restrict kernel selection to safe gpu kernels or safe dla kernels</span>
    <span class="s2">"num_min_timing_iters"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># Number of minimization timing iterations used to select kernels</span>
    <span class="s2">"num_avg_timing_iters"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># Number of averaging timing iterations used to select kernels</span>
    <span class="s2">"workspace_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum size of workspace given to TensorRT</span>
    <span class="s2">"max_batch_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum batch size (must be &gt;= 1 to be set, 0 means not set)</span>
<span class="p">}</span>
</pre>
              </div>
             </div>
             <p>
              Input Sizes can be specified as torch sizes, tuples or lists. Op precisions can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
             </p>
            </li>
           </ul>
          </dd>
          <dt class="field-even">
           Returns
          </dt>
          <dd class="field-even">
           <p>
            Serialized TensorRT engine, can either be saved to a file or deserialized via TensorRT APIs
           </p>
          </dd>
          <dt class="field-odd">
           Return type
          </dt>
          <dd class="field-odd">
           <p>
            bytes
           </p>
          </dd>
         </dl>
        </dd>
       </dl>
       <dl class="py function">
        <dt id="trtorch.check_method_op_support">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          check_method_op_support
         </code>
         <span class="sig-paren">
          (
         </span>
         <em class="sig-param">
          <span class="n">
           module
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           torch.jit._script.ScriptModule
          </span>
         </em>
         ,
         <em class="sig-param">
          <span class="n">
           method_name
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           str
          </span>
         </em>
         <span class="sig-paren">
          )
         </span>
         → bool
         <a class="headerlink" href="#trtorch.check_method_op_support" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Checks to see if a method is fully supported by TRTorch
         </p>
         <p>
          Checks if a method of a TorchScript module can be compiled by TRTorch, if not, a list of operators
that are not supported are printed out and the function returns false, else true.
         </p>
         <dl class="field-list simple">
          <dt class="field-odd">
           Parameters
          </dt>
          <dd class="field-odd">
           <ul class="simple">
            <li>
             <p>
              <strong>
               module
              </strong>
              (
              <em>
               torch.jit.ScriptModule
              </em>
              ) – Source module, a result of tracing or scripting a PyTorch
              <code class="docutils literal notranslate">
               <span class="pre">
                torch.nn.Module
               </span>
              </code>
             </p>
            </li>
            <li>
             <p>
              <strong>
               method_name
              </strong>
              (
              <em>
               str
              </em>
              ) – Name of method to check
             </p>
            </li>
           </ul>
          </dd>
          <dt class="field-even">
           Returns
          </dt>
          <dd class="field-even">
           <p>
            True if supported Method
           </p>
          </dd>
          <dt class="field-odd">
           Return type
          </dt>
          <dd class="field-odd">
           <p>
            bool
           </p>
          </dd>
         </dl>
        </dd>
       </dl>
       <dl class="py function">
        <dt id="trtorch.get_build_info">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          get_build_info
         </code>
         <span class="sig-paren">
          (
         </span>
         <span class="sig-paren">
          )
         </span>
         → str
         <a class="headerlink" href="#trtorch.get_build_info" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Returns a string containing the build information of TRTorch distribution
         </p>
         <dl class="field-list simple">
          <dt class="field-odd">
           Returns
          </dt>
          <dd class="field-odd">
           <p>
            String containing the build information for TRTorch distribution
           </p>
          </dd>
          <dt class="field-even">
           Return type
          </dt>
          <dd class="field-even">
           <p>
            str
           </p>
          </dd>
         </dl>
        </dd>
       </dl>
       <dl class="py function">
        <dt id="trtorch.dump_build_info">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          dump_build_info
         </code>
         <span class="sig-paren">
          (
         </span>
         <span class="sig-paren">
          )
         </span>
         <a class="headerlink" href="#trtorch.dump_build_info" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Prints build information about the TRTorch distribution to stdout
         </p>
        </dd>
       </dl>
       <dl class="py function">
        <dt id="trtorch.TensorRTCompileSpec">
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          TensorRTCompileSpec
         </code>
         <span class="sig-paren">
          (
         </span>
         <em class="sig-param">
          <span class="n">
           compile_spec
          </span>
          <span class="p">
           :
          </span>
          <span class="n">
           Dict
           <span class="p">
            [
           </span>
           str
           <span class="p">
            ,
           </span>
           Any
           <span class="p">
            ]
           </span>
          </span>
         </em>
         <span class="sig-paren">
          )
         </span>
         → &lt;torch._C.ScriptClass object at 0x7f55c3fab998&gt;
         <a class="headerlink" href="#trtorch.TensorRTCompileSpec" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Utility to create a formated spec dictionary for using the PyTorch TensorRT backend
         </p>
         <dl class="field-list simple">
          <dt class="field-odd">
           Parameters
          </dt>
          <dd class="field-odd">
           <p>
            <strong>
             compile_spec
            </strong>
            (
            <em>
             dict
            </em>
            ) –
           </p>
           <p>
            Compilation settings including operating precision, target device, etc.
One key is required which is
            <code class="docutils literal notranslate">
             <span class="pre">
              input_shapes
             </span>
            </code>
            , describing the input sizes or ranges for inputs
to the graph. All other keys are optional. Entries for each method to be compiled.
           </p>
           <div class="highlight-py notranslate">
            <div class="highlight">
             <pre><span></span><span class="n">CompileSpec</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"forward"</span> <span class="p">:</span> <span class="n">trtorch</span><span class="o">.</span><span class="n">TensorRTCompileSpec</span><span class="p">({</span>
        <span class="s2">"input_shapes"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="c1"># Static input shape for input #1</span>
            <span class="p">{</span>
                <span class="s2">"min"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
                <span class="s2">"opt"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
                <span class="s2">"max"</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
            <span class="p">}</span> <span class="c1"># Dynamic input shape for input #2</span>
        <span class="p">],</span>
        <span class="s2">"device"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"device_type"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">),</span> <span class="c1"># Type of device to run engine on (for DLA use trtorch.DeviceType.DLA)</span>
            <span class="s2">"gpu_id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Target gpu id to run engine (Use Xavier as gpu id for DLA)</span>
            <span class="s2">"dla_core"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># (DLA only) Target dla core id to run engine</span>
            <span class="s2">"allow_gpu_fallback"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span> <span class="c1"># (DLA only) Allow layers unsupported on DLA to run on GPU</span>
        <span class="p">},</span>
        <span class="s2">"op_precision"</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="c1"># Operating precision set to FP16</span>
        <span class="s2">"refit"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># enable refit</span>
        <span class="s2">"debug"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># enable debuggable engine</span>
        <span class="s2">"strict_types"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># kernels should strictly run in operating precision</span>
        <span class="s2">"capability"</span><span class="p">:</span> <span class="n">trtorch</span><span class="o">.</span><span class="n">EngineCapability</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">,</span> <span class="c1"># Restrict kernel selection to safe gpu kernels or safe dla kernels</span>
        <span class="s2">"num_min_timing_iters"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># Number of minimization timing iterations used to select kernels</span>
        <span class="s2">"num_avg_timing_iters"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># Number of averaging timing iterations used to select kernels</span>
        <span class="s2">"workspace_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum size of workspace given to TensorRT</span>
        <span class="s2">"max_batch_size"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Maximum batch size (must be &gt;= 1 to be set, 0 means not set)</span>
    <span class="p">})</span>
<span class="p">}</span>
</pre>
            </div>
           </div>
           <p>
            Input Sizes can be specified as torch sizes, tuples or lists. Op precisions can be specified using
torch datatypes or trtorch datatypes and you can use either torch devices or the trtorch device type enum
to select device type.
           </p>
          </dd>
          <dt class="field-even">
           Returns
          </dt>
          <dd class="field-even">
           <p>
            List of methods and formated spec objects to be provided to
            <code class="docutils literal notranslate">
             <span class="pre">
              torch._C._jit_to_tensorrt
             </span>
            </code>
           </p>
          </dd>
          <dt class="field-odd">
           Return type
          </dt>
          <dd class="field-odd">
           <p>
            torch.classes.tensorrt.CompileSpec
           </p>
          </dd>
         </dl>
        </dd>
       </dl>
       <h2 id="enums">
        Enums
        <a class="headerlink" href="#enums" title="Permalink to this headline">
         ¶
        </a>
       </h2>
       <dl class="py class">
        <dt id="trtorch.dtype">
         <em class="property">
          class
         </em>
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          dtype
         </code>
         <a class="headerlink" href="#trtorch.dtype" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Enum to specifiy operating precision for engine execution
         </p>
         <p>
          Members:
         </p>
         <blockquote>
          <div>
           <p>
            float : 32 bit floating point number
           </p>
           <p>
            float32 : 32 bit floating point number
           </p>
           <p>
            half : 16 bit floating point number
           </p>
           <p>
            float16 : 16 bit floating point number
           </p>
           <p>
            int8 : 8 bit integer number
           </p>
          </div>
         </blockquote>
        </dd>
       </dl>
       <dl class="py class">
        <dt id="trtorch.DeviceType">
         <em class="property">
          class
         </em>
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          DeviceType
         </code>
         <a class="headerlink" href="#trtorch.DeviceType" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Enum to specify device kinds to build TensorRT engines for
         </p>
         <p>
          Members:
         </p>
         <blockquote>
          <div>
           <p>
            GPU : Specify using GPU to execute TensorRT Engine
           </p>
           <p>
            DLA : Specify using DLA to execute TensorRT Engine (Jetson Only)
           </p>
          </div>
         </blockquote>
        </dd>
       </dl>
       <dl class="py class">
        <dt id="trtorch.EngineCapability">
         <em class="property">
          class
         </em>
         <code class="sig-prename descclassname">
          trtorch.
         </code>
         <code class="sig-name descname">
          EngineCapability
         </code>
         <a class="headerlink" href="#trtorch.EngineCapability" title="Permalink to this definition">
          ¶
         </a>
        </dt>
        <dd>
         <p>
          Enum to specify engine capability settings (selections of kernels to meet safety requirements)
         </p>
         <p>
          Members:
         </p>
         <blockquote>
          <div>
           <p>
            safe_gpu : Use safety GPU kernels only
           </p>
           <p>
            safe_dla : Use safety DLA kernels only
           </p>
           <p>
            default : Use default behavior
           </p>
          </div>
         </blockquote>
        </dd>
       </dl>
       <h2 id="submodules">
        Submodules
        <a class="headerlink" href="#submodules" title="Permalink to this headline">
         ¶
        </a>
       </h2>
       <div class="toctree-wrapper compound">
        <ul>
         <li class="toctree-l1">
          <a class="reference internal" href="logging.html">
           trtorch.logging
          </a>
         </li>
        </ul>
       </div>
      </article>
     </div>
    </div>
   </main>
  </div>
  <footer class="md-footer">
   <div class="md-footer-nav">
    <nav class="md-footer-nav__inner md-grid">
     <a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../_notebooks/ssd-object-detection-demo.html" rel="prev" title="Object Detection with TRTorch (SSD)">
      <div class="md-flex__cell md-flex__cell--shrink">
       <i class="md-icon md-icon--arrow-back md-footer-nav__button">
       </i>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
       <span class="md-flex__ellipsis">
        <span class="md-footer-nav__direction">
         Previous
        </span>
        Object Detection with TRTorch (SSD)
       </span>
      </div>
     </a>
     <a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="logging.html" rel="next" title="trtorch.logging">
      <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
       <span class="md-flex__ellipsis">
        <span class="md-footer-nav__direction">
         Next
        </span>
        trtorch.logging
       </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
       <i class="md-icon md-icon--arrow-forward md-footer-nav__button">
       </i>
      </div>
     </a>
    </nav>
   </div>
   <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
     <div class="md-footer-copyright">
      <div class="md-footer-copyright__highlight">
       © Copyright 2020, NVIDIA Corporation.
      </div>
      Created using
      <a href="http://www.sphinx-doc.org/">
       Sphinx
      </a>
      3.1.2.
             and
      <a href="https://github.com/bashtage/sphinx-material/">
       Material for
              Sphinx
      </a>
     </div>
    </div>
   </div>
  </footer>
  <script src="../_static/javascripts/application.js">
  </script>
  <script>
   app.initialize({version: "1.0.4", url: {base: ".."}})
  </script>
 </body>
</html>