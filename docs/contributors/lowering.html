


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Lowering Phase &mdash; Torch-TensorRT master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/collapsible-lists/css/tree_view.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Partitioning Phase" href="partitioning.html" />
    <link rel="prev" title="System Overview" href="system_overview.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.2.0a0+51a991e)
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/getting_started_with_python_api.html">Using Torch-TensorRT in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/getting_started_with_cpp_api.html">Using Torch-TensorRT in  C++</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/creating_torchscript_module_in_python.html">Creating a TorchScript Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/creating_torchscript_module_in_python.html#working-with-torchscript-in-python">Working with TorchScript in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/creating_torchscript_module_in_python.html#saving-torchscript-module-to-disk">Saving TorchScript Module to Disk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting_started_with_fx_path.html">Torch-TensorRT (FX Frontend) User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/ptq.html">Post Training Quantization (PTQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/runtime.html">Deploying Torch-TensorRT Programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/serving_torch_tensorrt_with_triton.html">Serving a Torch-TensorRT model with Triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/use_from_pytorch.html">Using Torch-TensorRT Directly From PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/using_dla.html">DLA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/notebooks.html">Example notebooks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API Documenation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../py_api/torch_tensorrt.html">torch_tensorrt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/logging.html">torch_tensorrt.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/ptq.html">torch_tensorrt.ptq</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/ts.html">torch_tensorrt.ts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py_api/fx.html">torch_tensorrt.fx</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C++ API Documenation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/torch_tensort_cpp.html">Torch-TensorRT C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt.html">Namespace torch_tensorrt</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__logging.html">Namespace torch_tensorrt::logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__torchscript.html">Namespace torch_tensorrt::torchscript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_cpp_api/namespace_torch_tensorrt__ptq.html">Namespace torch_tensorrt::ptq</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">CLI Documenation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cli/torchtrtc.html">torchtrtc</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contributor Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="system_overview.html">System Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="writing_converters.html">Writing Converters</a></li>
<li class="toctree-l1"><a class="reference internal" href="useful_links.html">Useful Links for Torch-TensorRT Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Indices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../indices/supported_ops.html">Operators Supported</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="system_overview.html">System Overview</a> &gt;</li>
        
      <li>Lowering Phase</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/contributors/lowering.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="lowering-phase">
<span id="lowering"></span><h1>Lowering Phase<a class="headerlink" href="#lowering-phase" title="Permalink to this headline">¶</a></h1>
<p>The lowering phase is made up out of passes which are operations which map a graph from a high level representation
to a lower level one. Each pass does something specific for instance inlining method calls. The idea is to
significantly reduce what the conversion phase needs to be able to handle when actually mapping to TensorRT.
We aim for closer to 1-&gt;1 op conversion vs looking for applicable subgraphs, limiting the number of converters and
reduce the scope of each converter.</p>
<p>You can see the effects of each pass by setting the log level to <code class="docutils literal notranslate"><span class="pre">Level::kGraph</span></code></p>
<section id="passes-used">
<h2>Passes Used<a class="headerlink" href="#passes-used" title="Permalink to this headline">¶</a></h2>
<section id="eliminatecommonsubexpression">
<h3>EliminateCommonSubexpression<a class="headerlink" href="#eliminatecommonsubexpression" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/common_subexpression_elimination.h">torch/csrc/jit/passes/common_subexpression_elimination.h</a></p>
</div></blockquote>
<p>Removes common subexpressions in the graph</p>
</section>
<section id="eliminate-dead-code">
<h3>Eliminate Dead Code<a class="headerlink" href="#eliminate-dead-code" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/dead_code_elimination.h">torch/csrc/jit/passes/dead_code_elimination.h</a></p>
</div></blockquote>
<p>Dead code elimination will check if a node has side effects and not delete it if it does.</p>
</section>
<section id="eliminate-exeception-or-pass-pattern">
<h3>Eliminate Exeception Or Pass Pattern<a class="headerlink" href="#eliminate-exeception-or-pass-pattern" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/exception_elimination.cpp">Torch-TensorRT/core/lowering/passes/exception_elimination.cpp</a></p>
</div></blockquote>
<p>A common pattern in scripted modules are dimension gaurds which will throw execptions if
the input dimension is not what was expected.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>%1013 : bool = aten::ne(%1012, %24) # ~/.local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py:248:11
    = prim::If(%1013) # ~/.local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py:248:8
    block0():
        = prim::RaiseException(%23) # ~/.local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py:249:12
    -&gt; ()
    block1():
    -&gt; ()
</pre></div>
</div>
<p>Since we are resolving all of this at compile time and there are no execptions in the TensorRT graph, we just remove it.</p>
</section>
<section id="eliminate-redundant-gaurds">
<h3>Eliminate Redundant Gaurds<a class="headerlink" href="#eliminate-redundant-gaurds" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/guard_elimination.h">torch/csrc/jit/passes/guard_elimination.h</a></p>
</div></blockquote>
<p>Eliminate redundant guards for ops whose outputs are fully determined by their inputs i.e. if inputs to such ops are
guarded we are allowed to remove a guard on ops’ outputs</p>
</section>
<section id="freeze-module">
<h3>Freeze Module<a class="headerlink" href="#freeze-module" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/freeze_module.h">torch/csrc/jit/passes/freeze_module.h</a></p>
</div></blockquote>
<p>Freeze attributes and inline constants and modules. Propogates constants in the graph.</p>
</section>
<section id="fuse-addmm-branches">
<h3>Fuse AddMM Branches<a class="headerlink" href="#fuse-addmm-branches" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/fuse_addmm_branches.cpp">Torch-TensorRT/core/lowering/passes/fuse_addmm_branches.cpp</a></p>
</div></blockquote>
<p>A common pattern in scripted modules is tensors of different dimensions use different constructions for implementing linear layers. We fuse these
different varients into a single one that will get caught by the Unpack AddMM pass.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>%ret : Tensor = prim::If(%622)
block0():
  %ret.1 : Tensor = aten::addmm(%self.fc.bias, %x9.1, %3677, %3, %3)
  -&gt; (%ret.1)
block1():
  %output.1 : Tensor = aten::matmul(%x9.1, %3677)
  %output0.1 : Tensor = aten::add_(%output.1, %self.fc.bias, %3)
  -&gt; (%output0.1)
</pre></div>
</div>
<p>We fuse this set of blocks into a graph like this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>%ret : Tensor = aten::addmm(%self.fc.bias, %x9.1, %3677, %3, %3)
</pre></div>
</div>
</section>
<section id="fuse-linear">
<h3>Fuse Linear<a class="headerlink" href="#fuse-linear" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/fuse_linear.h">torch/csrc/jit/passes/fuse_linear.h</a></p>
</div></blockquote>
<p>Match the <code class="docutils literal notranslate"><span class="pre">aten::linear</span></code> pattern and fuse it into a single <code class="docutils literal notranslate"><span class="pre">aten::linear</span></code>
This pass fuse the addmm or matmul + add generated by JIT back to linear</p>
</section>
<section id="fuse-flatten-linear">
<h3>Fuse Flatten Linear<a class="headerlink" href="#fuse-flatten-linear" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/fuse_flatten_linear.cpp">Torch-TensorRT/core/lowering/passes/fuse_flatten_linear.cpp</a></p>
</div></blockquote>
<p>TensorRT implicity flattens input layers into fully connected layers when they are higher than 1D. So when there is a
<code class="docutils literal notranslate"><span class="pre">aten::flatten</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">aten::linear</span></code> pattern we remove the <code class="docutils literal notranslate"><span class="pre">aten::flatten</span></code>.</p>
</section>
<section id="lower-graph">
<h3>Lower Graph<a class="headerlink" href="#lower-graph" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/lower_graph.h">torch/csrc/jit/passes/lower_graph.h</a></p>
</div></blockquote>
<p>Given a graph with of a method which first argument is %self, lower it to a graph where
all attributes accesses are replaced with explicit inputs of the graph
(rather than results of prim::GetAttr executed on %self). Returns a tuple
(graph, parameters) where the last module.parameters.size() inputs to the
graph are the trainable parameters used in this method. The remaining inputs
are the true inputs to the function.</p>
</section>
<section id="lower-tuples">
<h3>Lower Tuples<a class="headerlink" href="#lower-tuples" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/lower_tuples.h">torch/csrc/jit/passes/lower_tuples.h</a></p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LowerSimpleTuples</span></code>:</p></li>
</ul>
<p>Removes tuples where TupleConstruct and TupleUnpack are matched but leaves tuples in place across if statements, loops, and as inputs/outputs</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LowerAllTuples</span></code>:</p></li>
</ul>
<p>Removes _all_ tuples and raises an error if some cannot be removed, this is used by ONNX to ensure there are not tuples before conversion, but will not work on graphs whose inputs contain tuples.</p>
</section>
<section id="module-fallback">
<h3>Module Fallback<a class="headerlink" href="#module-fallback" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/module_fallback.cpp">Torch-TensorRT/core/lowering/passes/module_fallback.cpp</a></p>
</div></blockquote>
<p>Module fallback consists of two lowering passes that must be run as a pair. The first pass is run before freezing to place delimiters in the graph around modules
that should run in PyTorch. The second pass marks nodes between these delimiters after freezing to signify they should run in PyTorch.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">NotateModuleForFallback</span></code></p></li>
</ul>
<p>Places delimiting nodes around module calls pre freezing to signify where in the graph nodes should run in PyTorch</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MarkNodesForFallback</span></code></p></li>
</ul>
<p>Looks for delimiters then marks all nodes between the delimiters to tell partitioning to run them in PyTorch</p>
</section>
<section id="peephole-optimze">
<h3>Peephole Optimze<a class="headerlink" href="#peephole-optimze" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/ppeephole_optimze.h">torch/csrc/jit/passes/peephole_optimze.h</a></p>
</div></blockquote>
<p>The intent for this optimization pass is to catch all of the small, easy to catch peephole optimizations you might be interested in doing.</p>
<dl class="simple">
<dt>Right now, it does:</dt><dd><ul class="simple">
<li><p>Eliminate no-op ‘expand’ nodes</p></li>
<li><p>Simply x.t().t() to x</p></li>
</ul>
</dd>
</dl>
</section>
<section id="remove-contiguous">
<h3>Remove Contiguous<a class="headerlink" href="#remove-contiguous" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/remove_contiguous.cpp">Torch-TensorRT/core/lowering/passes/remove_contiguous.cpp</a></p>
</div></blockquote>
<p>Removes contiguous operators since we are doing TensorRT memory is already contiguous.</p>
</section>
<section id="remove-dropout">
<h3>Remove Dropout<a class="headerlink" href="#remove-dropout" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/remove_dropout.cpp">Torch-TensorRT/core/lowering/passes/remove_dropout.cpp</a></p>
</div></blockquote>
<p>Removes dropout operators since we are doing inference.</p>
</section>
<section id="remove-to">
<h3>Remove To<a class="headerlink" href="#remove-to" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/remove_to.cpp">Torch-TensorRT/core/lowering/passes/remove_to.cpp</a></p>
</div></blockquote>
<p>Removes <code class="docutils literal notranslate"><span class="pre">aten::to</span></code> operators that do casting, since TensorRT mangages it itself. It is important that this is one of the last passes run so that
other passes have a change to move required cast operators out of the main namespace.</p>
</section>
<section id="unpack-addmm">
<h3>Unpack AddMM<a class="headerlink" href="#unpack-addmm" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/unpack_addmm.cpp">Torch-TensorRT/core/lowering/passes/unpack_addmm.cpp</a></p>
</div></blockquote>
<p>Unpacks <code class="docutils literal notranslate"><span class="pre">aten::addmm</span></code> into <code class="docutils literal notranslate"><span class="pre">aten::matmul</span></code> and <code class="docutils literal notranslate"><span class="pre">aten::add_</span></code> (with an additional <code class="docutils literal notranslate"><span class="pre">trt::const</span></code>
op to freeze the bias in the TensorRT graph). This lets us reuse the <code class="docutils literal notranslate"><span class="pre">aten::matmul</span></code> and <code class="docutils literal notranslate"><span class="pre">aten::add_</span></code>
converters instead of needing a dedicated converter.</p>
</section>
<section id="unpack-logsoftmax">
<h3>Unpack LogSoftmax<a class="headerlink" href="#unpack-logsoftmax" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/TensorRT/blob/master/core/lowering/passes/unpack_log_softmax.cpp">Torch-TensorRT/core/lowering/passes/unpack_log_softmax.cpp</a></p>
</div></blockquote>
<p>Unpacks <code class="docutils literal notranslate"><span class="pre">aten::logsoftmax</span></code> into <code class="docutils literal notranslate"><span class="pre">aten::softmax</span></code> and <code class="docutils literal notranslate"><span class="pre">aten::log</span></code>. This lets us reuse the
<code class="docutils literal notranslate"><span class="pre">aten::softmax</span></code> and <code class="docutils literal notranslate"><span class="pre">aten::log</span></code> converters instead of needing a dedicated converter.</p>
</section>
<section id="unroll-loops">
<h3>Unroll Loops<a class="headerlink" href="#unroll-loops" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/passes/loop_unrolling.h">torch/csrc/jit/passes/loop_unrolling.h</a></p>
</div></blockquote>
<p>Unrolls the operations of compatable loops (e.g. sufficently short) so that you only have to go through the loop once.</p>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="partitioning.html" class="btn btn-neutral float-right" title="Partitioning Phase" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="system_overview.html" class="btn btn-neutral" title="System Overview" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, NVIDIA Corporation.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Lowering Phase</a><ul>
<li><a class="reference internal" href="#passes-used">Passes Used</a><ul>
<li><a class="reference internal" href="#eliminatecommonsubexpression">EliminateCommonSubexpression</a></li>
<li><a class="reference internal" href="#eliminate-dead-code">Eliminate Dead Code</a></li>
<li><a class="reference internal" href="#eliminate-exeception-or-pass-pattern">Eliminate Exeception Or Pass Pattern</a></li>
<li><a class="reference internal" href="#eliminate-redundant-gaurds">Eliminate Redundant Gaurds</a></li>
<li><a class="reference internal" href="#freeze-module">Freeze Module</a></li>
<li><a class="reference internal" href="#fuse-addmm-branches">Fuse AddMM Branches</a></li>
<li><a class="reference internal" href="#fuse-linear">Fuse Linear</a></li>
<li><a class="reference internal" href="#fuse-flatten-linear">Fuse Flatten Linear</a></li>
<li><a class="reference internal" href="#lower-graph">Lower Graph</a></li>
<li><a class="reference internal" href="#lower-tuples">Lower Tuples</a></li>
<li><a class="reference internal" href="#module-fallback">Module Fallback</a></li>
<li><a class="reference internal" href="#peephole-optimze">Peephole Optimze</a></li>
<li><a class="reference internal" href="#remove-contiguous">Remove Contiguous</a></li>
<li><a class="reference internal" href="#remove-dropout">Remove Dropout</a></li>
<li><a class="reference internal" href="#remove-to">Remove To</a></li>
<li><a class="reference internal" href="#unpack-addmm">Unpack AddMM</a></li>
<li><a class="reference internal" href="#unpack-logsoftmax">Unpack LogSoftmax</a></li>
<li><a class="reference internal" href="#unroll-loops">Unroll Loops</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
         <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
         <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>