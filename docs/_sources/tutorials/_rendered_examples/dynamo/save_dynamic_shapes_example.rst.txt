
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/_rendered_examples/dynamo/save_dynamic_shapes_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorials__rendered_examples_dynamo_save_dynamic_shapes_example.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials__rendered_examples_dynamo_save_dynamic_shapes_example.py:


.. _save_dynamic_shapes:

Saving and Loading Models with Dynamic Shapes
==============================================

This example demonstrates how to save and load Torch-TensorRT compiled models
with dynamic input shapes. When you compile a model with dynamic shapes,
you need to preserve the dynamic shape specifications when saving the model
to ensure it can handle variable input sizes after deserialization.

The API is designed to feel similar to torch.export's handling of dynamic shapes
for consistency and ease of use.

.. GENERATED FROM PYTHON SOURCE LINES 17-19

Imports and Model Definition
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 19-27

.. code-block:: python


    import tempfile

    import torch
    import torch.nn as nn
    import torch_tensorrt



.. GENERATED FROM PYTHON SOURCE LINES 28-29

Define a simple model that we'll compile with dynamic batch size

.. GENERATED FROM PYTHON SOURCE LINES 29-44

.. code-block:: python

    class MyModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = nn.Conv2d(3, 16, 3, stride=1, padding=1)
            self.relu = nn.ReLU()
            self.linear = nn.Linear(16 * 224 * 224, 10)

        def forward(self, x):
            x = self.conv(x)
            x = self.relu(x)
            x = x.flatten(1)
            x = self.linear(x)
            return x



.. GENERATED FROM PYTHON SOURCE LINES 45-48

Compile with Dynamic Shapes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
First, we compile the model with dynamic batch dimension

.. GENERATED FROM PYTHON SOURCE LINES 48-82

.. code-block:: python


    model = MyModel().eval().cuda()

    # Define example input with batch size 2
    example_input = torch.randn(2, 3, 224, 224).cuda()

    # Define dynamic batch dimension using torch.export.Dim
    # This allows batch sizes from 1 to 32
    dyn_batch = torch.export.Dim("batch", min=1, max=32)

    # Specify which dimensions are dynamic
    dynamic_shapes = {"x": {0: dyn_batch}}

    # Export the model with dynamic shapes
    exp_program = torch.export.export(
        model, (example_input,), dynamic_shapes=dynamic_shapes, strict=False
    )

    # Compile with Torch-TensorRT
    compile_spec = {
        "inputs": [
            torch_tensorrt.Input(
                min_shape=(1, 3, 224, 224),
                opt_shape=(8, 3, 224, 224),
                max_shape=(32, 3, 224, 224),
                dtype=torch.float32,
            )
        ],
        "enabled_precisions": {torch.float32},
        "min_block_size": 1,
    }

    trt_gm = torch_tensorrt.dynamo.compile(exp_program, **compile_spec)


.. GENERATED FROM PYTHON SOURCE LINES 83-85

Test Compiled Model with Different Batch Sizes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 85-94

.. code-block:: python


    # Test with batch size 4
    input_bs4 = torch.randn(4, 3, 224, 224).cuda()
    output_bs4 = trt_gm(input_bs4)

    # Test with batch size 16
    input_bs16 = torch.randn(16, 3, 224, 224).cuda()
    output_bs16 = trt_gm(input_bs16)


.. GENERATED FROM PYTHON SOURCE LINES 95-98

Save the Model with Dynamic Shapes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
The key is to pass the same dynamic_shapes specification to save()

.. GENERATED FROM PYTHON SOURCE LINES 98-126

.. code-block:: python


    with tempfile.TemporaryDirectory() as tmpdir:
        save_path = f"{tmpdir}/dynamic_model.ep"

        # Save with dynamic_shapes parameter - this is crucial for preserving dynamic behavior
        torch_tensorrt.save(
            trt_gm,
            save_path,
            output_format="exported_program",
            arg_inputs=[example_input],
            dynamic_shapes=dynamic_shapes,  # Same as used during export
        )

        # %%
        # Load and Test the Saved Model
        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        # Load the saved model
        loaded_model = torch_tensorrt.load(save_path).module()

        # Test with the same batch sizes to verify dynamic shapes are preserved
        output_loaded_bs4 = loaded_model(input_bs4)

        output_loaded_bs16 = loaded_model(input_bs16)

        assert torch.allclose(output_bs4, output_loaded_bs4, rtol=1e-3, atol=1e-3)
        assert torch.allclose(output_bs16, output_loaded_bs16, rtol=1e-3, atol=1e-3)


.. GENERATED FROM PYTHON SOURCE LINES 127-129

Example with Multiple Dynamic Dimensions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. GENERATED FROM PYTHON SOURCE LINES 129-184

.. code-block:: python



    class MultiDimModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = nn.Conv2d(3, 16, 3, stride=1, padding=1)

        def forward(self, x):
            return self.conv(x)


    model2 = MultiDimModel().eval().cuda()
    example_input2 = torch.randn(2, 3, 128, 128).cuda()

    # Define dynamic dimensions for batch and spatial dimensions
    dyn_batch2 = torch.export.Dim("batch", min=1, max=16)
    dyn_height = torch.export.Dim("height", min=64, max=512)
    dyn_width = torch.export.Dim("width", min=64, max=512)

    dynamic_shapes2 = {"x": {0: dyn_batch2, 2: dyn_height, 3: dyn_width}}

    exp_program2 = torch.export.export(
        model2, (example_input2,), dynamic_shapes=dynamic_shapes2, strict=False
    )

    compile_spec2 = {
        "inputs": [
            torch_tensorrt.Input(
                min_shape=(1, 3, 64, 64),
                opt_shape=(8, 3, 256, 256),
                max_shape=(16, 3, 512, 512),
                dtype=torch.float32,
            )
        ],
        "enabled_precisions": {torch.float32},
    }

    trt_gm2 = torch_tensorrt.dynamo.compile(exp_program2, **compile_spec2)

    with tempfile.TemporaryDirectory() as tmpdir:
        save_path2 = f"{tmpdir}/multi_dim_model.ep"

        torch_tensorrt.save(
            trt_gm2,
            save_path2,
            output_format="exported_program",
            arg_inputs=[example_input2],
            dynamic_shapes=dynamic_shapes2,
        )

        loaded_model2 = torch_tensorrt.load(save_path2).module()

        # Test with different input shapes
        test_input = torch.randn(4, 3, 256, 256).cuda()
        output = loaded_model2(test_input)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_tutorials__rendered_examples_dynamo_save_dynamic_shapes_example.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: save_dynamic_shapes_example.py <save_dynamic_shapes_example.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: save_dynamic_shapes_example.ipynb <save_dynamic_shapes_example.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
