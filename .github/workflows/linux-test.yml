name: Test on Linux

on:
  workflow_call:
    inputs:
      job-name:
        description: "Name of task"
        default: ""
        type: string
      repository:
        description: 'Repository to checkout, defaults to ""'
        default: ""
        type: string
      ref:
        description: 'Reference to checkout, defaults to "nightly"'
        default: "nightly"
        type: string
      pre-script:
        description: "Pre script to run prior to build"
        default: ""
        type: string
      test-infra-repository:
        description: "Test infra repository to use"
        default: "pytorch/test-infra"
        type: string
      test-infra-ref:
        description: "Test infra reference to use"
        default: ""
        type: string
      build-matrix:
        description: "Build matrix to utilize"
        default: ""
        type: string
      architecture:
        description: Architecture to build for x86_64 for default Linux, or aarch64 for Linux aarch64 builds
        required: false
        type: string
        default: x86_64
      setup-miniconda:
        description: Works as stated in actions/checkout, but the default value is recursive
        required: false
        type: boolean
        default: true
      script:
        description: 'Script to utilize'
        default: "python setup.py bdist_wheel"
        type: string
      continue-on-error:
        description: "Prevents a job from failing when a step fails. Set to true to allow a job to pass when exec script step fails."
        default: false
        type: boolean
      upload-artifact:
        description: 'Name to give artifacts uploaded from ${RUNNER_ARTIFACT_DIR}'
        default: ''
        type: string

jobs:
  test:
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(inputs.build-matrix) }}
    env:
      PYTHON_VERSION: ${{ matrix.python_version }}
      PACKAGE_TYPE: wheel
      REPOSITORY: ${{ inputs.repository }}
      REF: ${{ inputs.ref }}
      CU_VERSION: ${{ matrix.desired_cuda }}
      SCRIPT: ${{ inputs.script }}
      RUNNER_TEST_RESULTS_DIR: /tmp/test_results
      ARCH: ${{ inputs.architecture }}
      DOWNLOAD_ARTIFACT_NAME: pytorch_tensorrt_${{ matrix.tensorrt.version }}_${{ matrix.python_version }}_${{ matrix.desired_cuda }}_${{ inputs.architecture }}
    name: ${{ inputs.job-name }}-${{ matrix.tensorrt.version }}-${{ matrix.python_version }}-${{ matrix.desired_cuda }}
    runs-on: ${{ matrix.validation_runner }}
    container:
      image: ${{ matrix.container_image }}
      options: ${{ matrix.gpu_arch_type == 'cuda' && '--gpus all' || ' ' }}
    # If a build is taking longer than 120 minutes on these runners we need
    # to have a conversation
    timeout-minutes: 120
    steps:
      - name: Clean workspace
        run: |
          set -euxo pipefail
          echo "::group::Cleanup debug output"
          rm -rfv "${GITHUB_WORKSPACE}"
          mkdir -p "${GITHUB_WORKSPACE}"
          echo "::endgroup::"
      - uses: actions/checkout@v4
        with:
          # Support the use case where we need to checkout someone's fork
          repository: ${{ inputs.test-infra-repository }}
          ref: ${{ inputs.test-infra-ref }}
          path: test-infra
      - name: Setup SSH
        uses: ./test-infra/.github/actions/setup-ssh
        with:
          github-secret: ${{ github.token }}
      - uses: ./test-infra/.github/actions/set-channel
      - uses: ./test-infra/.github/actions/setup-binary-builds
        with:
          repository: ${{ inputs.repository }}
          ref: ${{ inputs.ref }}
          setup-miniconda: ${{ inputs.setup-miniconda }}
          python-version: ${{ env.PYTHON_VERSION }}
          cuda-version: ${{ env.CU_VERSION }}
          arch: ${{ env.ARCH }}
      - name: Run Pre-Script with Caching
        if: ${{ inputs.pre-script != '' }}
        uses: ./test-infra/.github/actions/run-script-with-cache
        with:
          cache-path: ${{ inputs.cache-path }}
          cache-key: ${{ inputs.cache-key }}
          repository: ${{ inputs.repository  }}
          script: ${{ inputs.pre-script }}
      - name: Download artifacts
        if: ${{ matrix.tensorrt == '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME }}
          path: /opt/torch-tensorrt-builds/
      - name: Download artifacts
        if: ${{ matrix.tensorrt != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.DOWNLOAD_ARTIFACT_NAME }}
          path: /opt/torch-tensorrt-builds/
      # - name: Install torch and torch-tensorrt
      #   if: ${{ inputs.pre-script != '' }}
      #   uses: ./test-infra/.github/actions/run-script-with-cache
      #   with:
      #     repository: ${{ inputs.repository  }}
      #     script: .github/scripts/install-torch-tensorrt.sh
      - name: Pack script
        continue-on-error: ${{ inputs.continue-on-error }}
        working-directory: ${{ inputs.repository }}
        env:
          ALL_SECRETS: ${{ toJSON(secrets) }}
        run: |
          set -euxo pipefail
          # shellcheck disable=SC2086
          source "${BUILD_ENV_FILE}"
          {
            echo "${SCRIPT}";
          } > "user_script"
          cat .github/scripts/install-torch-tensorrt.sh user_script > exec_script
      - name: Run Script
        uses: ./test-infra/.github/actions/run-script-with-cache
        with:
          repository: ${{ inputs.repository  }}
          script: exec_script
      - name: Surface failing tests
        if: always()
        uses: pmeier/pytest-results-action@v0.5.0
        with:
          path: ${{ env.RUNNER_TEST_RESULTS_DIR }}/**/*.xml
          summary: true
          display-options: fEs
          fail-on-empty: false

      - name: Prepare artifacts for upload
        working-directory: ${{ inputs.repository }}
        id: check-artifacts
        env:
          UPLOAD_ARTIFACT_NAME: ${{ inputs.upload-artifact }}
        run: |
          # Only do these steps if we actually want to upload an artifact
          if [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then
            # If the default execution path is followed then we should get a wheel in the dist/ folder
            # attempt to just grab whatever is in there and scoop it all up
            if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then
              mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"
            fi
            # Set to fail upload step if there are no files for upload and expected files for upload
            echo 'if-no-files-found=error' >> "${GITHUB_OUTPUT}"
          fi

          upload_docs=0
          # Check if there are things in the documentation folder to upload
          if find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 | read -r; then
            # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this
            # upload will probably not work correctly
            upload_docs=1
          fi
          echo "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"

      - name: Upload artifacts to GitHub (if any)
        uses: actions/upload-artifact@v4
        if: ${{ inputs.upload-artifact != '' }}
        with:
          name: ${{ inputs.upload-artifact }}
          path: ${{ runner.temp }}/artifacts/
          if-no-files-found: ${{ steps.check-artifacts.outputs.if-no-files-found }}

      - name: Upload documentation to S3 (if any)
        uses: seemethere/upload-artifact-s3@v5
        if: ${{ steps.check-artifacts.outputs.upload-docs == 1 && github.event.pull_request.number != '' }}
        with:
          retention-days: 14
          s3-bucket: doc-previews
          if-no-files-found: error
          path: ${{ env.RUNNER_DOCS_DIR }}
          # ${{ env.repository }} is $OWNER/$REPO
          s3-prefix: ${{ env.REPOSITORY }}/${{ github.event.pull_request.number }}

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ inputs.repository }}-${{ github.event_name == 'workflow_dispatch' }}-${{ inputs.job-name }}
  cancel-in-progress: true
