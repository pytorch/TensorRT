{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c9db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a2575",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/tesla/notebook_assets/nv_logo_torch_trt_resnet_notebook.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Masked Language Modeling (MLM) with Hugging Face BERT Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e39bd5",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the practice of developing machine learning models, there are few tools as approachable as PyTorch for developing and experimenting in designing machine learning models. The power of PyTorch comes from its deep integration into Python, its flexibility and its approach to automatic differentiation and execution (eager execution). However, when moving from research into production, the requirements change and we may no longer want that deep Python integration and we want optimization to get the best performance we can on our deployment platform. In PyTorch 1.0, TorchScript was introduced as a method to separate your PyTorch model from Python, make it portable and optimizable. TorchScript uses PyTorch's JIT compiler to transform your normal PyTorch code which gets interpreted by the Python interpreter to an intermediate representation (IR) which can have optimizations run on it and at runtime can get interpreted by the PyTorch JIT interpreter. For PyTorch this has opened up a whole new world of possibilities, including deployment in other languages like C++. It also introduces a structured graph based format that we can use to do down to the kernel level optimization of models for inference.\n",
    "\n",
    "When deploying on NVIDIA GPUs TensorRT, NVIDIA's Deep Learning Optimization SDK and Runtime is able to take models from any major framework and specifically tune them to perform better on specific target hardware in the NVIDIA family be it an A100, TITAN V, Jetson Xavier or NVIDIA's Deep Learning Accelerator. TensorRT performs a couple sets of optimizations to achieve this. TensorRT fuses layers and tensors in the model graph, it then uses a large kernel library to select implementations that perform best on the target GPU. TensorRT also has strong support for reduced operating precision execution which allows users to leverage the Tensor Cores on Volta and newer GPUs as well as reducing memory and computation footprints on device.\n",
    "\n",
    "Torch-TensorRT is a compiler that uses TensorRT to optimize TorchScript code, compiling standard TorchScript modules into ones that internally run with TensorRT optimizations. This enables you to continue to remain in the PyTorch ecosystem, using all the great features PyTorch has such as module composability, its flexible tensor implementation, data loaders and more. Torch-TensorRT is available to use with both PyTorch and LibTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c98cf",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "This notebook demonstrates the steps for compiling a TorchScript module with Torch-TensorRT on a pretrained SSD network, and running it to test the speedup obtained.\n",
    "\n",
    "## Contents\n",
    "1. [Requirements](#1)\n",
    "2. [BERT Overview](#2)\n",
    "3. [Creating TorchScript modules](#3)\n",
    "4. [Compiling with Torch-TensorRT](#4)\n",
    "5. [Benchmarking](#5)\n",
    "6. [Conclusion](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf99b1",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Requirements\n",
    "\n",
    "NVIDIA's NGC provides a PyTorch Docker Container which contains PyTorch and Torch-TensorRT. We can make use of [latest pytorch](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) container to run this notebook.\n",
    "\n",
    "Otherwise, you can follow the steps in `notebooks/README` to prepare a Docker container yourself, within which you can run this demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2582ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6bc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import argparse\n",
    "import timeit\n",
    "import numpy as np\n",
    "import torch_tensorrt\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c62811",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. BERT Overview\n",
    "\n",
    "Transformers comprise a class of deep learning algorithms employing self-attention; broadly speaking, the models learn large matrices of numbers, each element of which denotes how important one component of input data is to another. Since their introduction in 2017, transformers have enjoyed widespread adoption, particularly in natural language processing, but also in computer vision problems. This is largely because they are easier to parallelize than the sequence models which attention mechanisms were originally designed to augment. \n",
    "\n",
    "Hugging Face is a company that maintains a huge respository of pre-trained transformer models. The company also provides tools for integrating those models into PyTorch code and running inference with them. \n",
    "\n",
    "One of the most popular transformer models is BERT (Bidirectional Encoder Representations from Transformers). First developed at Google and released in 2018, it has become the backbone of Google's search engine and a standard benchmark for NLP experiments. BERT was originally trained for next sentence prediction and masked language modeling (MLM), which aims to predict hidden words in sentences. In this notebook, we will use Hugging Face's `bert-base-uncased` model (BERT's smallest and simplest form, which does not employ text capitalization) for MLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5b360",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Creating TorchScript modules  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491fe4e",
   "metadata": {},
   "source": [
    "First, create a pretrained BERT tokenizer from the `bert-base-uncased` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b540c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad2ff6",
   "metadata": {},
   "source": [
    "Create dummy inputs to generate a traced TorchScript model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d9ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = [101, 64]*64\n",
    "segments_ids = [0, 1]*64\n",
    "attention_masks = [1, 1]*64\n",
    "batched_indexed_tokens = []\n",
    "batched_segments_ids = []\n",
    "batched_attention_masks = []\n",
    "for i in range(batch_size):\n",
    "    batched_indexed_tokens.append(indexed_tokens)\n",
    "    batched_segments_ids.append(segments_ids)\n",
    "    batched_attention_masks.append(attention_masks)\n",
    "\n",
    "# Creating dummy inputs\n",
    "tokens_tensor = torch.tensor(batched_indexed_tokens)\n",
    "segments_tensor = torch.tensor(batched_segments_ids)\n",
    "attention_masks_tensor = torch.tensor(batched_attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842e896",
   "metadata": {},
   "source": [
    "Obtain a scripted TorchScript model from Hugging Face, then use the dummy inputs to trace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646b6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "mlm_model_ts = BertForMaskedLM.from_pretrained('bert-base-uncased', torchscript=True)\n",
    "traced_mlm_model = torch.jit.trace(mlm_model_ts, [tokens_tensor, segments_tensor, attention_masks_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc3354",
   "metadata": {},
   "source": [
    "Define 4 masked sentences, with 1 word in each sentence hidden from the model. Fluent English speakers will probably be able to guess the masked words, but just in case, they are `'capital'`, `'language'`, `'innings'`, and `'mathematics'`.\n",
    "\n",
    "Also create a list containing the position of the masked word within each sentence. Given Python's 0-based indexing convention, the numbers are each higher by 1 than might be expected. This is because the token at index 0 in each sentence is a beginning-of-sentence token, denoted `[CLS]` when entered explicitly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3955ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_sentences = ['Paris is the [MASK] of France.', \n",
    "                    'The primary [MASK] of the United States is English.', \n",
    "                    'A baseball game consists of at least nine [MASK].', \n",
    "                    'Topology is a branch of [MASK] concerned with the properties of geometric objects that remain unchanged under continuous transformations.']\n",
    "pos_masks = [4, 3, 9, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a608d86",
   "metadata": {},
   "source": [
    "Pass the masked sentences into the (scripted) TorchScript MLM model and verify that the unmasked sentences yield the expected results.  \n",
    "\n",
    "Because the sentences are of different lengths, we must specify the `padding` argument in calling our encoder/tokenizer. There are several possible padding strategies, but we'll use `'max_length'` padding with `max_length=128`. Later, when we compile an optimized version of the model with Torch-TensorRT, the optimized model will expect inputs of length 128, hence our choice of padding strategy and length here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9512531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of France.\n",
      "The primary language of the United States is English.\n",
      "A baseball game consists of at least nine innings.\n",
      "Topology is a branch of mathematics concerned with the properties of geometric objects that remain unchanged under continuous transformations.\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = enc(masked_sentences, return_tensors='pt', padding='max_length', max_length=128)\n",
    "outputs = mlm_model_ts(**encoded_inputs)\n",
    "most_likely_token_ids = [torch.argmax(outputs[0][i, pos, :]) for i, pos in enumerate(pos_masks)]\n",
    "unmasked_tokens = enc.decode(most_likely_token_ids).split(' ')\n",
    "unmasked_sentences = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens)]\n",
    "for sentence in unmasked_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b16185",
   "metadata": {},
   "source": [
    "Pass the masked sentences into the traced MLM model and verify that the unmasked sentences yield the expected results. \n",
    "\n",
    "Note the difference in how the `encoded_inputs` are passed into the model in the following cell compared to the previous one. If you examine `encoded_inputs`, you'll find that it's a dictionary with 3 keys, `'input_ids'`, `'token_type_ids'`, and `'attention_mask'`, each with a PyTorch tensor as an associated value. The traced model will accept `**encoded_inputs` as an input, but the Torch-TensorRT-optimized model (to be defined later) will not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab44932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of France.\n",
      "The primary language of the United States is English.\n",
      "A baseball game consists of at least nine innings.\n",
      "Topology is a branch of mathematics concerned with the properties of geometric objects that remain unchanged under continuous transformations.\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = enc(masked_sentences, return_tensors='pt', padding='max_length', max_length=128)\n",
    "outputs = traced_mlm_model(encoded_inputs['input_ids'], encoded_inputs['token_type_ids'], encoded_inputs['attention_mask'])\n",
    "most_likely_token_ids = [torch.argmax(outputs[0][i, pos, :]) for i, pos in enumerate(pos_masks)]\n",
    "unmasked_tokens = enc.decode(most_likely_token_ids).split(' ')\n",
    "unmasked_sentences = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens)]\n",
    "for sentence in unmasked_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4dc477",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Compiling with Torch-TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7bb91a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input input_ids, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for input_ids\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT] - For input attention_mask.1, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Double\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for attention_mask.1\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT] - For input token_type_ids, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for token_type_ids\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Tensor DataType is determined at build time for tensors not marked as input or output.\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(traced_mlm_model, \n",
    "    inputs= [torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32),\n",
    "             torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32),\n",
    "             torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32)],\n",
    "    enabled_precisions= {torch.float32}, # Run with 32-bit precision\n",
    "    workspace_size=2000000000,\n",
    "    truncate_long_and_double=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc88e2",
   "metadata": {},
   "source": [
    "Pass the masked sentences into the compiled model and verify that the unmasked sentences yield the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ebde07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch-TensorRT model unmasked sentences:\n",
      "Paris is the capital of France.\n",
      "The primary language of the United States is English.\n",
      "A baseball game consists of at least nine innings.\n",
      "Topology is a branch of mathematics concerned with the properties of geometric objects that remain unchanged under continuous transformations.\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = enc(masked_sentences, return_tensors='pt', padding='max_length', max_length=128)\n",
    "enc_inputs = {k: v.type(torch.int32).cuda() for k, v in enc_inputs.items()}\n",
    "output_trt = trt_model(enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "most_likely_token_ids_trt = [torch.argmax(output_trt[i, pos, :]) for i, pos in enumerate(pos_masks)] \n",
    "unmasked_tokens_trt = enc.decode(most_likely_token_ids_trt).split(' ')\n",
    "unmasked_sentences_trt = [masked_sentences[i].replace('[MASK]', token) for i, token in enumerate(unmasked_tokens_trt)]\n",
    "print('Torch-TensorRT model unmasked sentences:')\n",
    "for sentence in unmasked_sentences_trt:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44c9df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input input_ids, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for input_ids\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT] - For input attention_mask.1, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Double\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for attention_mask.1\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT] - For input token_type_ids, found user specified input dtype as Int32, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Int32\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for token_type_ids\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Tensor DataType is determined at build time for tensors not marked as input or output.\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Int64 to Int32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior us"
     ]
    }
   ],
   "source": [
    "trt_model_fp16 = torch_tensorrt.compile(traced_mlm_model, \n",
    "    inputs= [torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32),\n",
    "             torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32),\n",
    "             torch_tensorrt.Input(shape=[batch_size, 128], dtype=torch.int32)],\n",
    "    enabled_precisions= {torch.half}, # Run with 16-bit precision\n",
    "    workspace_size=2000000000,\n",
    "    truncate_long_and_double=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0405f",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2b7f9",
   "metadata": {},
   "source": [
    "This function passes the inputs into the model and runs inference `num_loops` times, then returns a list of length containing the amount of time in seconds that each instance of inference took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e345f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ing dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - Truncating weight (constant in the graph) from Float64 to Float32\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n"
     ]
    }
   ],
   "source": [
    "def timeGraph(model, input_tensor1, input_tensor2, input_tensor3, num_loops=50):\n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(20):\n",
    "            features = model(input_tensor1, input_tensor2, input_tensor3)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_loops):\n",
    "            start_time = timeit.default_timer()\n",
    "            features = model(input_tensor1, input_tensor2, input_tensor3)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = timeit.default_timer()\n",
    "            timings.append(end_time - start_time)\n",
    "            # print(\"Iteration {}: {:.6f} s\".format(i, end_time - start_time))\n",
    "\n",
    "    return timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21fbc6",
   "metadata": {},
   "source": [
    "This function prints the number of input batches the model is able to process each second and summary statistics of the model's latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "503c8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(graphName, timings, batch_size):\n",
    "    times = np.array(timings)\n",
    "    steps = len(times)\n",
    "    speeds = batch_size / times\n",
    "    time_mean = np.mean(times)\n",
    "    time_med = np.median(times)\n",
    "    time_99th = np.percentile(times, 99)\n",
    "    time_std = np.std(times, ddof=0)\n",
    "    speed_mean = np.mean(speeds)\n",
    "    speed_med = np.median(speeds)\n",
    "\n",
    "    msg = (\"\\n%s =================================\\n\"\n",
    "            \"batch size=%d, num iterations=%d\\n\"\n",
    "            \"  Median FPS: %.1f, mean: %.1f\\n\"\n",
    "            \"  Median latency: %.6f, mean: %.6f, 99th_p: %.6f, std_dev: %.6f\\n\"\n",
    "            ) % (graphName,\n",
    "                batch_size, steps,\n",
    "                speed_med, speed_mean,\n",
    "                time_med, time_mean, time_99th, time_std)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39630e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a12727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random input tensor of certain size\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "input_tensor1 = torch.randint(0, 2, (batch_size, 128), dtype=torch.int32).cuda()\n",
    "input_tensor2 = torch.randint(0, 2, (batch_size, 128), dtype=torch.int32).cuda()\n",
    "input_tensor3 = torch.randint(0, 2, (batch_size, 128), dtype=torch.int32).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71599dcc",
   "metadata": {},
   "source": [
    "Benchmark the (scripted) TorchScript model on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c273072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 17.8, mean: 17.8\n",
      "  Median latency: 0.225295, mean: 0.225056, 99th_p: 0.228187, std_dev: 0.000916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(mlm_model_ts, encoded_inputs['input_ids'], encoded_inputs['token_type_ids'], encoded_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1f8ef",
   "metadata": {},
   "source": [
    "Benchmark the traced model on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bc16a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 18.3, mean: 18.3\n",
      "  Median latency: 0.218376, mean: 0.218163, 99th_p: 0.219516, std_dev: 0.000648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(traced_mlm_model, encoded_inputs['input_ids'], encoded_inputs['token_type_ids'], encoded_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f851f1",
   "metadata": {},
   "source": [
    "Benchmark the (scripted) TorchScript model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cafd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 571.7, mean: 572.3\n",
      "  Median latency: 0.006997, mean: 0.006991, 99th_p: 0.007270, std_dev: 0.000067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(mlm_model_ts.cuda(), enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6dc58",
   "metadata": {},
   "source": [
    "Benchmark the traced model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "017c4bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 927.6, mean: 928.2\n",
      "  Median latency: 0.004312, mean: 0.004309, 99th_p: 0.004345, std_dev: 0.000018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(traced_mlm_model.cuda(), enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec11ff5",
   "metadata": {},
   "source": [
    "Benchmark the compiled FP32 model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46ce6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 1222.9, mean: 1216.0\n",
      "  Median latency: 0.003271, mean: 0.003290, 99th_p: 0.003351, std_dev: 0.000033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(trt_model, enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3745f19",
   "metadata": {},
   "source": [
    "Benchmark the compiled FP16 model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a9c813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=4, num iterations=50\n",
      "  Median FPS: 1798.6, mean: 1808.4\n",
      "  Median latency: 0.002224, mean: 0.002213, 99th_p: 0.002254, std_dev: 0.000049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timings = timeGraph(trt_model_fp16, enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8aa64",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we have walked through the complete process of compiling TorchScript models with Torch-TensorRT for Masked Language Modeling with Hugging Face's `bert-base-uncased` transformer and testing the performance impact of the optimization. With Torch-TensorRT on an NVIDIA A100 GPU, we observe the speedups indicated below. These acceleration numbers will vary from GPU to GPU (as well as implementation to implementation based on the ops used) and we encorage you to try out latest generation of Data center compute cards for maximum acceleration.\n",
    "\n",
    "Scripted (GPU): 1.0x\n",
    "Traced (GPU): 1.62x\n",
    "Torch-TensorRT (FP32): 2.14x\n",
    "Torch-TensorRT (FP16): 3.15x\n",
    "\n",
    "### What's next\n",
    "Now it's time to try Torch-TensorRT on your own model. If you run into any issues, you can fill them at https://github.com/NVIDIA/Torch-TensorRT. Your involvement will help future development of Torch-TensorRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
